---
layout: post
title: 인공지능 및 기계학습개론 1강(2) - MAP
category: Machine Learning
tag: [ML Introduction, MAP]
---

이글에서는 문일철 교수님의 <b>[인공지능 및 기계학습 개론](https://www.edwith.org/machinelearning1_17)</b>  강의의 Chapter 1의 내용 중 MAP part를 요약하고 필요한 내용을 보충설명한다. 

# Chapter 1. Motivations and Basics

## MAP(Maximum A Posterior estimation) 

앞서 압정을 던지는 trial(5번 중 3번이 head, 2번이 tail)을 통해 head가 나올 확률을 [MLE 관점](https://dswwfg.github.io/machine%20learning/2019/02/16/ML/)에서 60%로 예측하였다. 이번 강의에서는 <b>MAP(Maximum A Posterior estimation)</b>라는 다른 예측 방법을 배운다. 

MAP을 이해하기 위해서 3가지를 먼저 다루는게 좋다. 
- <b>사전확률(Prior probability)</b>: 특정 결과가 일어나기 전의 확률 
- <b>사후확률(Posterior probability)</b>: 특정 결과가 이미 일어났는데 이의 원인에 대한 확률
- <b>베이즈 정리(Bayes' theorem)</b>: 두 확률 변수 사이의 사전 확률과 사후 확률의 관계를 나타내는 정리

간단한 예를 사용하여 위의 3가지 용어들을 다뤄보고자 한다.
<p align="center">
  <img src="https://github.com/dswwfg/dswwfg.github.io/blob/master/public/post_img/2019-02-17-Intro-ML-1/prior_posterior.PNG?raw=true" width="500">
</p>

위의 그림에서, 빨간색, 초록색 구슬을 담은 2개의 통 A, B가 있다. A는 5개의 빨간색, 10개의 초록색 구슬이 담겨있고, B는 10개의 빨간색, 5개의 초록색 구슬이 담겨져있다. 

이 때, 두개의 통 중 임의로 하나가 선택 되어, 선택된 10개의 공 샘플 $\boldsymbol{X}=(X_1, X_2, \cdots, X_{10})$이 있고  빨간공 4개, 초록색 공 6개라고 생각해보자. 

공을 뽑기 전에, 통 A, B가 선택될 확률, 즉 <b>사전 확률</b>$P(A), P(B)$을 각각 $\frac{1}{2}$ 이라고 가정한다. 우리는 이 공들이 통 A, B에서 뽑힌 확률 $P\left(A\mid \boldsymbol{X} \right)$와 $P\left(B\mid \boldsymbol{X} \right)$을 알고자 한다. 이를 <b>사후 확률</b>이라 한다. 사후 확률을 구하기 어렵기 때문에 <b>베이즈 정리</b>를 이용해 사전확률과 가능도(likelihood)의 곱셈으로 나타낼 수 있다. 

- <b>베이즈 정리</b>

$$
P(A|\boldsymbol{X})=\frac{P(\boldsymbol{X}|A)P(A)}{P(\boldsymbol{X})}
$$

$$
P(B|\boldsymbol{X})=\frac{P(\boldsymbol{X}|B)P(B)}{P(\boldsymbol{X})}
$$

$P(\boldsymbol{X}\mid A)$, $P(\boldsymbol{X}\mid B)$는 통 A, B 안의 공의 구성을 알고 있으므로 구할 수 있다.

$$
P(\boldsymbol{X}|A) = (\frac{1}{3})^4(\frac{2}{3})^6
$$

$$
P(\boldsymbol{X}|B) = (\frac{2}{3})^4(\frac{1}{3})^6
$$

최종적으로 사후 확률을 구해보면 아래와 같다.

$$
\begin{align*}
P(A|\boldsymbol{X})&=\frac{P(\boldsymbol{X}|A)P(A)}{P(\boldsymbol{X})}=\frac{P(\boldsymbol{X}|A)P(A)}{P(\boldsymbol{X}|A)P(A)+P(\boldsymbol{X}|B)P(B)}
\\\\
&=\frac{(\frac{1}{3})^4(\frac{2}{3})^6}{(\frac{1}{3})^4(\frac{2}{3})^6 + (\frac{2}{3})^4(\frac{1}{3})^6} = \frac{4}{5}
\end{align*}
$$


$$
\begin{align*}
P(B|\boldsymbol{X})&=\frac{P(\boldsymbol{X}|B)P(B)}{P(\boldsymbol{X})}=\frac{P(\boldsymbol{X}|B)P(B)}{P(\boldsymbol{X}|A)P(A)+P(\boldsymbol{X}|B)P(B)}
\\\\
&=\frac{(\frac{2}{3})^4(\frac{1}{3})^6}{(\frac{1}{3})^4(\frac{2}{3})^6 + (\frac{2}{3})^4(\frac{1}{3})^6} = \frac{1}{5}
\end{align*}
$$
 
다시 압정 던지기 예로 돌아가서 위의 예와 비교하면서 MAP에 대해 이해해보자. 압정을 던져서 head가 나올 확률을 사후 확률로 $P\left(\theta\mid D\right)$로 표현할 수 있다. 이는 베이즈 정리에 따라 아래와 같이 표현할 수 있다. 

$$
P\left(\theta\mid D\right)=\frac{P\left(D\mid\theta\right)P(\theta)}{P(D)}
$$

$P\left(D\mid\theta\right)$는 MAP에서 다뤘던 likelihood function으로 $P\left(D\mid\theta\right)=\theta^{a_H}(1-\theta)^{a_T}$와 같이 표현할 수 있고 $P(\theta)$는 사전 확률로 이전 경험이나, 직관을 통해 표현할 수 있다. 강의에서는 Beta distribution이란걸 통해서 $P(\theta)$를 표현하고 있다. 이유는 압정의 head가 나올 확률인 $\theta$의 범위 모두 0$\le \theta\le 1$로 Beta distribution의 범위와 일치하기 때문이다. 

<p align="center">
<img src="https://github.com/dswwfg/dswwfg.github.io/blob/master/public/post_img/2019-02-17-Intro-ML-1/beta_distribution.png?raw=true" width="500">
</p>

$$
P(\theta)=\frac{\theta^{\alpha-1}(1-\theta)^{\beta-1}}{B(\alpha, \beta)}, B(\alpha, \beta)=\frac{\Gamma(\alpha)	\Gamma(\beta)}{\Gamma(\alpha+\beta)}, \Gamma(\alpha)=(\alpha-1)!
$$


$P(\theta)$를 이용해서 사후확률 $P\left(\theta \mid D\right)$를 아래와 같이 나타낼 수 있다. 

$$
\begin{align*}
P\left(\theta \mid D\right) &\propto P\left(D\mid\theta\right)P(\theta) \propto \theta^{a_H}(1-\theta)^{a_T}\theta^{\alpha-1}(1-\theta)^{\beta-1}
\\\\ & = \theta^{a_H+\alpha-1}(1-\theta)^{a_T+\beta-1}
\end{align*}
$$ 

<b>MAP</b>는 사후 확률을 최대로 만드는 statistical model의 parameter를 찾는 것으로 아래와 같이 표현할 수 있다.

$$
\begin{align*}
\hat\theta&=argmax_\theta P\left(\theta\mid D\right)\\\\
&\propto argmax_\theta\{\theta^{a_H+\alpha-1}(1-\theta)^{a_T+\beta-1}\}\\\\
&\propto argmax_\theta ln\{ {\theta^{a_H+\alpha-1}(1-\theta)^{a_T+\beta-1}}\}\\\\
&=argmax_\theta\{(a_H+\alpha-1)ln\theta+(a_T+\beta-1)ln(1-\theta)\}
\end{align*}
$$


$\theta$의 최대값을 찾기 위해 $\theta$에 대해  편미분하면 아래와 같다.

$$
\begin{align*}
&\frac{d}{d\theta}\{(a_H+\alpha-1)ln\theta+(a_T+\beta-1)ln(1-\theta)\}\\\\
&=\frac{a_H+\alpha-1}{\theta}-\frac{a_T+\beta-1}{1-\theta}\\\\
&=\frac{a_H+\alpha-1-a_H\theta-\alpha\theta+\theta-a_T\theta-\beta\theta+\theta}{\theta(1-\theta)}\\\\
&=\frac{\theta(-a_H-a_T-\alpha-\beta+2)+a_H+\alpha-1}{\theta(1-\theta)}=0\\\\
&\therefore\hat\theta=\frac{a_H+\alpha-1}{a_H+a_T+\alpha+\beta-2}
\end{align*}
$$

### references
- https://mathcs.clarku.edu/~djoyce/ma218/bayes1.pdf
