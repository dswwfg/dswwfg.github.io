---
layout: post
title: 인공지능 및 기계학습개론 1강(1) - MLE
category: Machine Learning
tag: [ML Introduction, MLE]
---

이글에서는 문일철 교수님의 <b>[인공지능 및 기계학습 개론](https://www.edwith.org/machinelearning1_17)</b>  강의의 Chapter 1을 요약하고 필요한 내용을 보충설명한다. 

# Chapter 1. Motivations and Basics

먼저 머신러닝의 정의는 아래와 같다.

><b>Machine learning (ML)</b> is the scientific study of algorithms and statistical models that computer systems use to effectively perform a specific task without using explicit instructions, relying on patterns and inference instead.

즉, <b>머신러닝</b>은 컴퓨터가 특정 task를 효과적으로 수행하기 위해 사용하는 알고리즘이나 통계적 모델에 대한 연구인데 분명한, 구체적인 명령없이 경험이라고 할 수 있는 기존의 데이터로부터 패턴이나 추론을 통해 task를 수행하는 것이다.
<p align="center">
  <img src="https://github.com/dswwfg/dswwfg.github.io/blob/master/public/post_img/2019-02-17-Intro-ML-1/types_of_ml.PNG?raw=true" width="500">
</p>

본 강의에서는 머신러닝의 종류들 중 Supervised Learning과 Unsupervised Learning에 대해서 설명한다. 

## Supervised Learning vs Unsupervised Learning
<img src="https://github.com/dswwfg/dswwfg.github.io/blob/master/public/post_img/2019-02-17-Intro-ML-1/sup_vs_unsup.png?raw=true">



<b>Supervised learning</b>(지도학습)의 정의는 아래와 같다.

> <b>Supervised learning</b> is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.

즉, Supervised learning은 input과 output의 짝으로 구성된 데이터로부터, input을 output으로 mapping 시키는 function을 배우는 task이다. 이렇게 학습된 function은 미래의 input으로부터 output을 예측하는데 사용 될 수 있다.

Supervised learning은 크게 classification과 regression으로 나뉠 수 있다. Classification은 discrete dependent value(혹은 output)을 예측하는 것이고 (ex) 특정메일이 스팸메일인지 아닌지 분류), Regression은 continuous dependent value를 예측하는 것이다.(ex) 데이터들로부터 curve fitting)

반면, <b>Unsupervised learning</b>(비지도학습)의 정의는 아래와 같다.

><b>Unsupervised learning</b> is a branch of machine learning that learns from test data that has not been labeled, classified or categorized.

Supervised learning과의 차이점은, output data가 없는 input data만을 이용해서 데이터가 어떻게 구성되어있는지를 알아내는 것이다. 예로, 수 많은 text data로부터 대표적인 주제단어를 찾는 문제에 쓰일 수 있다. 

## MLE (Maximum Likelihood Estimation)

MLE를 설명하기 전, 강의에서 압정을 던지는 예제가 나온다. 압정을 던지기 전 압정의 방향을 배팅해서, 압정을 던져 나온 방향과 일치할 경우 돈을 버는 도박이 있다. <b>압정의 방향은 뾰족한 부분(nail)이 위로 오는 경우와 아닌 경우만 있다고 가정해보자.</b> 각각 경우의 확률은 어떻고, 어떤 방향으로 배팅을 해야하는가?

<p align="center">
	<img src="https://github.com/dswwfg/dswwfg.github.io/blob/master/public/post_img/2019-02-17-Intro-ML-1/exp_from_trial.PNG?raw=true" width="500">
</p>

압정을 몇번 던져보고 결정하기로 하고 위의 그림과 같이, 뾰족한 부분이 위로 오는 경우(nail's up case)가 3번, 반대의 경우(nail's down case)가 2번 나왔다고 생각해보자. 5번의 던진 경험을 통해 '뾰족한 부분이 위로 올 확률이 3/5이므로 반대의 경우보다 더 높다' 라고 추정하는 것. 이것이 MLE이다. 

MLE의 정의는 아래와 같다. 
> <b>maximum likelihood estimation (MLE)</b> is a method of estimating the parameters of a statistical model, given observations. The method obtains the parameter estimates by finding the parameter values that maximize the likelihood function.

위 정의의 설명에서 그 동안 언급되지 않은 2가지 단어가 나온다. <b>the parameters of a statistical model, likelihood function</b>

* <b>Statistical model</b>이란 수학적 모델로, 데이터를 생성하는데 연관된 통계적 가정(statistical assumption)을 포함한다.<br>
 예를 들어, 앞서 압정을 던졌을 때, <b>압정의 방향은 두가지(뾰족한 부분이 위 or 아래)의 경우만 있다고 가정</b>했으므로 Bionomial distribution(이항분포)를 따른다고 가정해보자. Bionomial distribution은 연속된 시행횟수 n과 각 시행이 가질 확률 $\theta$를 parameter로 가지는 discrete probability distribution이고, 뾰족한 부분이 위로 나올 확률을 $\theta$라고 해보자. 위의 예에서 압정을 5번 던졌으므로, n=5이고, 우리는 MLE를 통해 $\theta$를 예측 할 수 있다. 

* <b>Likelihood function</b>은 관찰된 데이터가 주어졌을 때, statistical model의 parameter에 대한 function으로 구체적으로는, $\theta$가 given일 때, 관찰된 데이터의 사건(up=3번, down=2번)이 나올 가능성이다. 
$$
L(\theta)=P\left( D\mid \theta \right) = \theta^{a_H}(1-\theta)^{a_T}
$$
 위의 예에서, 5번의 압정을 던진 데이터가 주어졌고, 뾰족한 부분이 위로 나올 확률을 $\theta$로 했을 때, Likelihood function은 위와 같다. $a_H$는 up이 나온 횟수, $a_T$는 down이 나온 횟수이다. 
<b>최종적으로 MLE는 데이터들이 나올 likelihood function을 가장 크게 하는 statistical model의 parameter $\theta$를 찾는 것이고 이를 예측된 parameter $\hat\theta$라고 할 수 있다. $\theta$ 를 찾는 식이므로, $L(\theta)$로 표현하기도 한다.</b>

$$
\hat\theta=argmax_\theta P\left(D\mid \theta \right)
$$

$$
\hat\theta=argmax_\theta P\left(D\mid \theta \right)=argmax_\theta \theta^{a_H}(1-\theta)^{a_T}
$$

위에서 $\theta$ 를 구하기 위해 log function을 취한다. log function은 단조증가 함수인데 이는 log function을 취한 likelihood function을 최대화하는 $\theta$값과 likelihood function을 최대화하는 $\theta$ 값이 같음을 의미한다.

$$
\hat\theta=argmax_\theta lnP\left(D\mid \theta \right)=argmax_\theta ln\{\theta^{a_H}(1-\theta)^{a_T}\}
$$
$$
= argmax_\theta \{a_Hln\theta+a_Tln(1-\theta) \}
$$

위 식을 maximize하기 위한 $\theta$ 값을 구하기 위해, $\theta$에 대해 미분 후 0이 되는 $\theta$를 구한다.

$$
\frac{d}{d\theta}(a_Hln\theta+a_Tln(1-\theta))=\frac{a_H}{\theta}-\frac{a_T}{1-\theta}=0
$$

$$
\frac{a_H(1-\theta)-a_T\theta}{\theta(1-\theta)}=0, a_H-a_H\theta-a_T\theta=0, a_H=\theta(a_H+a_T)
$$

$$
 \therefore\hat\theta=\frac{a_H}{a_H+a_T}
$$

정리해서, $\theta$는 압정의 뾰족한 윗부분이 나올 확률로, MLE 에 의해 압정을 5번의 던진 경험(3번 up, 2번 down)을 통해 parameter $\theta$ 값을 $\frac{3}{5}$ 라고 예측할 수 있다.  

## 추가 예
무작위로 추출된 사람들의 키가 아래와 같고, 아래의 키들은 정규 분포(normal distribution)을 따른다고 한다. 

    115 122 130 127 149 160 152 138 149 180

likelihood function과 MLE를 통해 $\mu$ 와 $\sigma^2$값을 찾아보자.

먼저, 주어진 키 값들은 normal distribution을 따른다고 했으므로, parameter는 $\mu$와 $\sigma^2$ 이고 probability density function(pdf)는 아래와 같다. 

$$
f(x_i;\mu,\sigma^2) = \frac{1}{\sigma\sqrt{2\pi}}\exp[-\frac{(x_i-\mu)^2}{2\sigma^2}]=\sigma^{-1}(2\pi)^{-\frac{1}{2}}\exp[-\frac{(x_i-\mu)^2}{2\sigma^2}]
$$

likelihood function은 아래와 같다.

$$
\begin{align*}
L(\mu, \sigma^2 ; x_1,... ,x_n)&= f(x_1,... ,x_n;\mu, \sigma^2)\\&=f(x_1;\mu, \sigma^2)*f(x_2;\mu, \sigma^2)\cdots*f(x_n;\mu,\sigma^2)\\ &=\prod_{i=1}^{n}f(x_i;\mu, \sigma^2)={\sigma^2}^{(\frac{-n}{2})}(2\pi)^{-\frac{n}{2}}\exp[-\frac{\sum_{i=1}^{n}(x_i-\mu)^2}{2\sigma^2}]
\end{align*}
$$

계산의 편의를 위해 likelihood function에 자연로그를 취하면 아래와 같다.

$$
ln(L(\mu, \sigma^2 ; x_1,... ,x_n))=-\frac{n}{2}ln\sigma^2-\frac{n}{2}ln(2\pi)-\frac{\sum_{i=1}^{n}(x_i-\mu)^2}{2\sigma^2}
$$

앞의 예와 마찬가지로, likelihood function을 최대로하는 $\mu$를 찾기 위해 $\mu$에 대한 partial derivative 를 취하면, 아래와 같다.

$$
\frac{d}{d\mu}ln(L(\mu, \sigma^2 ; x_1,... ,x_n))=\frac{\sum_{i=1}^{n}(x_i-\mu)}{\sigma^2} = 0, \sum_{i=1}^{n}x_i-n\mu=0
$$

$$
\therefore \hat\mu=\frac{\sum_{i=1}^{n}x_i}{n}=\frac{115+122+130+127+149+160+152+138+149+180}{10}=142.2
$$

이번에는 likelihood function을 최대로 하는 $\sigma^2$를 찾기 위해 $\sigma^2$에 대한 partial derivative를 취하면 아래와 같다.

$$
\frac{d}{d\sigma^2}ln(L(\mu, \sigma^2 ; x_1,... ,x_n))=-\frac{n}{2\sigma^2}+\frac{\sum_{i=1}^{n}(x_i-\mu)^2}{2(\sigma^2)^2}=0, \frac{-n\sigma^2+\sum_{i=1}^{n}(x_i-\mu)^2}{2(\sigma^2)^2}=0
$$

$$
, \therefore \hat\sigma^2=\frac{\sum_{i=1}^{n}(x_i-\mu)^2}{n} = \frac{(115-142.2)^2+\cdots+(180-142.2)^2}{10} = 347.96
$$

## Simple Error Bound
<p align="center">
<img src="https://github.com/dswwfg/dswwfg.github.io/blob/master/public/post_img/2019-02-17-Intro-ML-1/simple error bound.PNG?raw=true" width="500">
</p>

다시 압정을 던지는 예로 돌아가보자. 압정을 5번 던지는 경험으로부터 MLE관점에서 $\theta$를 예측해서 0.6이라는 값을 얻었다. 5번의 압정을 던져 3번의 경우가 압정의 뾰족한 부분이 나온 것과 50번 던져서 30번의 경우 압정의 뾰족한 부분이 위로 나와서, $\frac{30}{30+20}=\frac{3}{5}$의 $\hat\theta$값을 얻은 경우는 같은 것인가? 

<b>당연히 그렇지 않다. </b>
추가적인 압정을 던지는 시도는 estimation의 error을 줄일 수 있다. MLE를 통해 우리가 얻은 paramter $\hat\theta$는 추정치이다. 우리가 현실에서는 알 수 없지만 실제의 parameter를 $\theta^\star$라고 할 때, Hoeffding's inequality에 의해 아래와 같이, 확률의 upper bound를 가질 수 있다. 

$$
P(|\hat\theta-\theta^\star|\ge\epsilon)\le2e^{-2N\epsilon^2}
$$

위 식에서 N은 trial 횟수인데, N이 커질수록 우변의 값이 작아져서 실제 parameter와 예측된 parameter의 error가 발생할 확률의 upper bound를 줄여준다. 예를 들어, 두 parameter 차이의 최소값($\epsilon$)이 0.1일 확률을 0.01% 이하로 만들어 줄 수 있는 trial N을 구할 수 있다. 이를 <b>PAC(Probably Approxim=ate Correct) Learning</b>이라고도 하는데, 이는 우변의 확률 내에서 ,그리고 $\epsilon$ 값의 오차범위 내에서는 correct 한 learning의 결과물인 $\hat\theta$가 PAC Learning의 결과물이라고 할 수 있다.

